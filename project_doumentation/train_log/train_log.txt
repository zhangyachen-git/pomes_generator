Epoch: 0, batch: 0, training loss: 4.040528Epoch: 0, batch: 1, training loss: 4.553360Epoch: 0, batch: 2, training loss: 3.897478Epoch: 0, batch: 3, training loss: 4.244896Epoch: 0, batch: 4, training loss: 3.952645Epoch: 0, batch: 5, training loss: 3.965577Epoch: 0, batch: 6, training loss: 5.313889Epoch: 0, batch: 7, training loss: 3.956049Epoch: 0, batch: 8, training loss: 3.436737Epoch: 0, batch: 9, training loss: 4.757196Epoch: 0, batch: 10, training loss: 3.739376Epoch: 0, batch: 11, training loss: 3.992579Epoch: 0, batch: 12, training loss: 3.590867Epoch: 0, batch: 13, training loss: 4.200319Epoch: 0, batch: 14, training loss: 3.401412Epoch: 0, batch: 15, training loss: 4.224732Epoch: 0, batch: 16, training loss: 3.742903Epoch: 0, batch: 17, training loss: 3.549894Epoch: 0, batch: 18, training loss: 3.187773Epoch: 0, batch: 19, training loss: 2.639836Epoch: 0, batch: 20, training loss: 3.664994Epoch: 0, batch: 21, training loss: 3.539131Epoch: 0, batch: 22, training loss: 4.149785Epoch: 0, batch: 23, training loss: 3.569844Epoch: 0, batch: 24, training loss: 3.523755Epoch: 0, batch: 25, training loss: 4.108936Epoch: 0, batch: 26, training loss: 4.025694Epoch: 0, batch: 27, training loss: 3.946010Epoch: 0, batch: 28, training loss: 4.346550Epoch: 0, batch: 29, training loss: 4.232607Epoch: 0, batch: 30, training loss: 4.325068Epoch: 0, batch: 31, training loss: 3.696575Epoch: 0, batch: 32, training loss: 3.331832Epoch: 0, batch: 33, training loss: 5.695122Epoch: 0, batch: 34, training loss: 5.738421Epoch: 0, batch: 35, training loss: 4.102010Epoch: 0, batch: 36, training loss: 4.060903Epoch: 0, batch: 37, training loss: 4.149580Epoch: 0, batch: 38, training loss: 4.062258Epoch: 0, batch: 39, training loss: 4.715129Epoch: 0, batch: 40, training loss: 3.672660Epoch: 0, batch: 41, training loss: 3.903700Epoch: 0, batch: 42, training loss: 4.001740Epoch: 0, batch: 43, training loss: 3.742649Epoch: 0, batch: 44, training loss: 4.287367Epoch: 0, batch: 45, training loss: 4.033086Epoch: 0, batch: 46, training loss: 3.912562Epoch: 0, batch: 47, training loss: 4.156408Epoch: 0, batch: 48, training loss: 3.883183Epoch: 0, batch: 49, training loss: 4.142975Epoch: 1, batch: 0, training loss: 3.770041Epoch: 1, batch: 1, training loss: 4.308820Epoch: 1, batch: 2, training loss: 3.561284Epoch: 1, batch: 3, training loss: 4.114802Epoch: 1, batch: 4, training loss: 3.593139Epoch: 1, batch: 5, training loss: 3.639070Epoch: 1, batch: 6, training loss: 4.856656Epoch: 1, batch: 7, training loss: 3.650483Epoch: 1, batch: 8, training loss: 3.190479Epoch: 1, batch: 9, training loss: 4.388319Epoch: 1, batch: 10, training loss: 3.566825Epoch: 1, batch: 11, training loss: 3.899161Epoch: 1, batch: 12, training loss: 3.486302Epoch: 1, batch: 13, training loss: 4.126807Epoch: 1, batch: 14, training loss: 3.303614Epoch: 1, batch: 15, training loss: 4.140431Epoch: 1, batch: 16, training loss: 3.676000Epoch: 1, batch: 17, training loss: 3.495684Epoch: 1, batch: 18, training loss: 3.116848Epoch: 1, batch: 19, training loss: 2.580550Epoch: 1, batch: 20, training loss: 3.574019Epoch: 1, batch: 21, training loss: 3.332099Epoch: 1, batch: 22, training loss: 3.913972Epoch: 1, batch: 23, training loss: 3.423243Epoch: 1, batch: 24, training loss: 3.381735Epoch: 1, batch: 25, training loss: 3.935971Epoch: 1, batch: 26, training loss: 3.860322Epoch: 1, batch: 27, training loss: 3.823706Epoch: 1, batch: 28, training loss: 4.219806Epoch: 1, batch: 29, training loss: 4.077979Epoch: 1, batch: 30, training loss: 4.164125Epoch: 1, batch: 31, training loss: 3.549837Epoch: 1, batch: 32, training loss: 3.200641Epoch: 1, batch: 33, training loss: 5.435543Epoch: 1, batch: 34, training loss: 5.484240Epoch: 1, batch: 35, training loss: 3.933998Epoch: 1, batch: 36, training loss: 3.900809Epoch: 1, batch: 37, training loss: 3.949775Epoch: 1, batch: 38, training loss: 3.902534Epoch: 1, batch: 39, training loss: 4.556602Epoch: 1, batch: 40, training loss: 3.531883Epoch: 1, batch: 41, training loss: 3.749191Epoch: 1, batch: 42, training loss: 3.843091Epoch: 1, batch: 43, training loss: 3.576680Epoch: 1, batch: 0, training loss: 3.626446Epoch: 1, batch: 1, training loss: 4.176813Epoch: 1, batch: 2, training loss: 3.401867Epoch: 1, batch: 3, training loss: 4.021844Epoch: 1, batch: 4, training loss: 3.349129Epoch: 1, batch: 5, training loss: 3.393633Epoch: 1, batch: 6, training loss: 4.463425Epoch: 1, batch: 7, training loss: 3.414408Epoch: 1, batch: 8, training loss: 3.007292Epoch: 1, batch: 9, training loss: 4.132189Epoch: 1, batch: 10, training loss: 3.384091Epoch: 1, batch: 11, training loss: 3.664393Epoch: 1, batch: 12, training loss: 3.366324Epoch: 1, batch: 13, training loss: 3.983847Epoch: 1, batch: 14, training loss: 3.267381Epoch: 1, batch: 15, training loss: 4.079512Epoch: 1, batch: 16, training loss: 3.555644Epoch: 1, batch: 17, training loss: 3.408178Epoch: 1, batch: 18, training loss: 3.050495Epoch: 2, batch: 0, training loss: 3.357190Epoch: 2, batch: 1, training loss: 3.853606Epoch: 2, batch: 2, training loss: 2.913479Epoch: 2, batch: 3, training loss: 3.673991Epoch: 2, batch: 4, training loss: 2.772231Epoch: 2, batch: 5, training loss: 2.837076Epoch: 2, batch: 6, training loss: 3.543325Epoch: 2, batch: 7, training loss: 2.844631Epoch: 2, batch: 8, training loss: 2.602432Epoch: 2, batch: 9, training loss: 3.757311Epoch: 2, batch: 10, training loss: 3.168745Epoch: 2, batch: 11, training loss: 3.448631Epoch: 2, batch: 12, training loss: 3.119209Epoch: 2, batch: 13, training loss: 3.725593Epoch: 2, batch: 14, training loss: 3.041054Epoch: 2, batch: 15, training loss: 3.828023Epoch: 2, batch: 16, training loss: 3.369560Epoch: 2, batch: 17, training loss: 3.206150Epoch: 2, batch: 18, training loss: 2.827620Epoch: 2, batch: 19, training loss: 2.313897Epoch: 2, batch: 20, training loss: 3.358397Epoch: 2, batch: 21, training loss: 2.884641Epoch: 2, batch: 22, training loss: 3.542780Epoch: 2, batch: 23, training loss: 3.197041Epoch: 2, batch: 24, training loss: 3.135451Epoch: 2, batch: 25, training loss: 3.645585Epoch: 2, batch: 26, training loss: 3.585457Epoch: 2, batch: 27, training loss: 3.574542Epoch: 2, batch: 28, training loss: 3.946027Epoch: 2, batch: 29, training loss: 3.782895Epoch: 2, batch: 30, training loss: 3.897935Epoch: 2, batch: 31, training loss: 3.286543Epoch: 2, batch: 32, training loss: 2.984731Epoch: 2, batch: 33, training loss: 4.973310Epoch: 2, batch: 34, training loss: 5.034063Epoch: 2, batch: 35, training loss: 3.648643Epoch: 2, batch: 36, training loss: 3.593349Epoch: 2, batch: 37, training loss: 3.596644Epoch: 2, batch: 38, training loss: 3.614850Epoch: 2, batch: 39, training loss: 4.274318Epoch: 2, batch: 40, training loss: 3.225602Epoch: 2, batch: 41, training loss: 3.469876Epoch: 2, batch: 42, training loss: 3.557372Epoch: 2, batch: 43, training loss: 3.201416Epoch: 2, batch: 44, training loss: 3.907000Epoch: 2, batch: 45, training loss: 3.705876Epoch: 2, batch: 46, training loss: 3.622816Epoch: 2, batch: 47, training loss: 3.758975Epoch: 2, batch: 48, training loss: 3.448155Epoch: 2, batch: 49, training loss: 3.715094Epoch: 3, batch: 0, training loss: 3.262976Epoch: 3, batch: 1, training loss: 3.681287Epoch: 3, batch: 2, training loss: 2.793159Epoch: 3, batch: 3, training loss: 3.536788Epoch: 3, batch: 4, training loss: 2.634690Epoch: 3, batch: 5, training loss: 2.691614Epoch: 3, batch: 6, training loss: 3.280733Epoch: 3, batch: 7, training loss: 2.639120Epoch: 3, batch: 8, training loss: 2.407296Epoch: 3, batch: 9, training loss: 3.381974Epoch: 3, batch: 10, training loss: 2.964902Epoch: 3, batch: 11, training loss: 3.273557Epoch: 3, batch: 12, training loss: 2.954439Epoch: 3, batch: 13, training loss: 3.537128Epoch: 3, batch: 14, training loss: 2.892540Epoch: 3, batch: 15, training loss: 3.641303Epoch: 3, batch: 16, training loss: 3.221999Epoch: 3, batch: 17, training loss: 3.069515Epoch: 3, batch: 18, training loss: 2.713001Epoch: 3, batch: 19, training loss: 2.206522Epoch: 3, batch: 20, training loss: 3.220217Epoch: 3, batch: 21, training loss: 2.697986Epoch: 3, batch: 22, training loss: 3.348087Epoch: 3, batch: 23, training loss: 3.037824Epoch: 3, batch: 24, training loss: 2.994952Epoch: 3, batch: 25, training loss: 3.476917Epoch: 3, batch: 26, training loss: 3.434024Epoch: 3, batch: 27, training loss: 3.455914Epoch: 3, batch: 28, training loss: 3.778485Epoch: 3, batch: 29, training loss: 3.591559Epoch: 3, batch: 30, training loss: 3.734250Epoch: 3, batch: 31, training loss: 3.133920Epoch: 3, batch: 32, training loss: 2.870562Epoch: 3, batch: 33, training loss: 4.675806Epoch: 3, batch: 34, training loss: 4.737034Epoch: 3, batch: 35, training loss: 3.505390Epoch: 3, batch: 36, training loss: 3.461782Epoch: 3, batch: 37, training loss: 3.401662Epoch: 3, batch: 38, training loss: 3.456378Epoch: 3, batch: 39, training loss: 4.127041Epoch: 3, batch: 40, training loss: 3.074273Epoch: 3, batch: 41, training loss: 3.319406Epoch: 3, batch: 42, training loss: 3.404973Epoch: 3, batch: 43, training loss: 3.025921Epoch: 3, batch: 44, training loss: 3.774618Epoch: 3, batch: 45, training loss: 3.561577Epoch: 3, batch: 46, training loss: 3.485091Epoch: 3, batch: 47, training loss: 3.585761Epoch: 3, batch: 48, training loss: 3.285958Epoch: 3, batch: 49, training loss: 3.559540Epoch: 4, batch: 0, training loss: 3.195406Epoch: 4, batch: 1, training loss: 3.564085Epoch: 4, batch: 2, training loss: 2.620280Epoch: 4, batch: 3, training loss: 3.418639Epoch: 4, batch: 4, training loss: 2.400403Epoch: 4, batch: 5, training loss: 2.489374Epoch: 4, batch: 6, training loss: 2.934204Epoch: 4, batch: 7, training loss: 2.432381Epoch: 4, batch: 8, training loss: 2.286196Epoch: 4, batch: 9, training loss: 3.132271Epoch: 4, batch: 10, training loss: 2.805118Epoch: 4, batch: 11, training loss: 3.096744Epoch: 4, batch: 12, training loss: 2.786719Epoch: 4, batch: 13, training loss: 3.346594Epoch: 4, batch: 14, training loss: 2.758837Epoch: 4, batch: 15, training loss: 3.486337Epoch: 4, batch: 16, training loss: 3.083536Epoch: 4, batch: 17, training loss: 2.949303Epoch: 4, batch: 18, training loss: 2.605861Epoch: 4, batch: 19, training loss: 2.111163Epoch: 4, batch: 20, training loss: 3.089988Epoch: 4, batch: 21, training loss: 2.547890Epoch: 4, batch: 22, training loss: 3.160322Epoch: 4, batch: 23, training loss: 2.882012Epoch: 4, batch: 24, training loss: 2.845717Epoch: 4, batch: 25, training loss: 3.279755Epoch: 4, batch: 26, training loss: 3.253435Epoch: 4, batch: 27, training loss: 3.297965Epoch: 4, batch: 28, training loss: 3.635139Epoch: 4, batch: 29, training loss: 3.449527Epoch: 4, batch: 30, training loss: 3.565093Epoch: 4, batch: 31, training loss: 2.972450Epoch: 4, batch: 32, training loss: 2.762831Epoch: 4, batch: 33, training loss: 4.416698Epoch: 4, batch: 34, training loss: 4.453854Epoch: 4, batch: 35, training loss: 3.325938Epoch: 4, batch: 36, training loss: 3.304848Epoch: 4, batch: 37, training loss: 3.311746Epoch: 4, batch: 38, training loss: 3.362903Epoch: 4, batch: 39, training loss: 3.960489Epoch: 4, batch: 40, training loss: 2.907814Epoch: 4, batch: 41, training loss: 3.236971Epoch: 4, batch: 42, training loss: 3.383265Epoch: 4, batch: 43, training loss: 2.918896Epoch: 4, batch: 44, training loss: 3.625035Epoch: 4, batch: 45, training loss: 3.411186Epoch: 4, batch: 46, training loss: 3.383266Epoch: 4, batch: 47, training loss: 3.484610Epoch: 4, batch: 48, training loss: 3.177825Epoch: 4, batch: 49, training loss: 3.405908Epoch: 5, batch: 0, training loss: 3.097788Epoch: 5, batch: 1, training loss: 3.437394Epoch: 5, batch: 2, training loss: 2.512060Epoch: 5, batch: 3, training loss: 3.341606Epoch: 5, batch: 4, training loss: 2.238433Epoch: 5, batch: 5, training loss: 2.341383Epoch: 5, batch: 6, training loss: 2.657494Epoch: 5, batch: 7, training loss: 2.254688Epoch: 5, batch: 8, training loss: 2.166102Epoch: 5, batch: 9, training loss: 2.900983Epoch: 5, batch: 10, training loss: 2.684196Epoch: 5, batch: 11, training loss: 2.953014Epoch: 5, batch: 12, training loss: 2.666242Epoch: 5, batch: 13, training loss: 3.213195Epoch: 5, batch: 14, training loss: 2.661285Epoch: 5, batch: 15, training loss: 3.381647Epoch: 5, batch: 16, training loss: 2.955567Epoch: 5, batch: 17, training loss: 2.841656Epoch: 5, batch: 18, training loss: 2.510746Epoch: 5, batch: 19, training loss: 2.022650Epoch: 5, batch: 20, training loss: 2.967514Epoch: 5, batch: 21, training loss: 2.390100Epoch: 5, batch: 22, training loss: 3.001261Epoch: 5, batch: 23, training loss: 2.746778Epoch: 5, batch: 24, training loss: 2.739404Epoch: 5, batch: 25, training loss: 3.139723Epoch: 5, batch: 26, training loss: 3.118350Epoch: 5, batch: 27, training loss: 3.157665Epoch: 5, batch: 28, training loss: 3.458175Epoch: 5, batch: 29, training loss: 3.243591Epoch: 5, batch: 30, training loss: 3.394475Epoch: 5, batch: 31, training loss: 2.850813Epoch: 5, batch: 32, training loss: 2.669308Epoch: 5, batch: 33, training loss: 4.094559Epoch: 5, batch: 34, training loss: 4.119971Epoch: 5, batch: 35, training loss: 3.181152Epoch: 5, batch: 36, training loss: 3.157961Epoch: 5, batch: 37, training loss: 3.107685Epoch: 5, batch: 38, training loss: 3.204437Epoch: 5, batch: 39, training loss: 3.793640Epoch: 5, batch: 40, training loss: 2.781873Epoch: 5, batch: 41, training loss: 3.096357Epoch: 5, batch: 42, training loss: 3.205111Epoch: 5, batch: 43, training loss: 2.762441Epoch: 5, batch: 44, training loss: 3.517694Epoch: 5, batch: 45, training loss: 3.311922Epoch: 5, batch: 46, training loss: 3.281283Epoch: 5, batch: 47, training loss: 3.282886Epoch: 5, batch: 48, training loss: 2.958065Epoch: 5, batch: 49, training loss: 3.238608Epoch: 6, batch: 0, training loss: 2.981625Epoch: 6, batch: 1, training loss: 3.347447Epoch: 6, batch: 2, training loss: 2.328872Epoch: 6, batch: 3, training loss: 3.194981Epoch: 6, batch: 4, training loss: 2.023004Epoch: 6, batch: 5, training loss: 2.161114Epoch: 6, batch: 6, training loss: 2.390454Epoch: 6, batch: 7, training loss: 2.083011Epoch: 6, batch: 8, training loss: 1.997607Epoch: 6, batch: 9, training loss: 2.626872Epoch: 6, batch: 10, training loss: 2.547552Epoch: 6, batch: 11, training loss: 2.825817Epoch: 6, batch: 12, training loss: 2.551623Epoch: 6, batch: 13, training loss: 3.062336Epoch: 6, batch: 14, training loss: 2.570583Epoch: 6, batch: 15, training loss: 3.251740Epoch: 6, batch: 16, training loss: 2.823749Epoch: 6, batch: 17, training loss: 2.737438Epoch: 6, batch: 18, training loss: 2.436359Epoch: 6, batch: 19, training loss: 1.959309Epoch: 6, batch: 20, training loss: 2.838665Epoch: 6, batch: 21, training loss: 2.259123Epoch: 6, batch: 22, training loss: 2.844877Epoch: 6, batch: 23, training loss: 2.625678Epoch: 6, batch: 24, training loss: 2.628829Epoch: 6, batch: 25, training loss: 2.985005Epoch: 6, batch: 26, training loss: 2.981158Epoch: 6, batch: 27, training loss: 3.039986Epoch: 6, batch: 28, training loss: 3.329601Epoch: 6, batch: 29, training loss: 3.093894Epoch: 6, batch: 30, training loss: 3.213620Epoch: 6, batch: 31, training loss: 2.683452Epoch: 6, batch: 32, training loss: 2.534444Epoch: 6, batch: 33, training loss: 3.779874Epoch: 6, batch: 34, training loss: 3.784263Epoch: 6, batch: 35, training loss: 3.010912Epoch: 6, batch: 36, training loss: 2.976182Epoch: 6, batch: 37, training loss: 2.912283Epoch: 6, batch: 38, training loss: 3.029617Epoch: 6, batch: 39, training loss: 3.637014Epoch: 6, batch: 40, training loss: 2.612170Epoch: 6, batch: 41, training loss: 2.922213Epoch: 6, batch: 42, training loss: 3.034559Epoch: 6, batch: 43, training loss: 2.597122Epoch: 6, batch: 44, training loss: 3.332928Epoch: 6, batch: 45, training loss: 3.168264Epoch: 6, batch: 46, training loss: 3.144310Epoch: 6, batch: 47, training loss: 3.113094Epoch: 6, batch: 48, training loss: 2.811189Epoch: 6, batch: 49, training loss: 3.058520Epoch: 7, batch: 0, training loss: 2.833591Epoch: 7, batch: 1, training loss: 3.160360Epoch: 7, batch: 2, training loss: 2.145849Epoch: 7, batch: 3, training loss: 3.048214Epoch: 7, batch: 4, training loss: 1.851236Epoch: 7, batch: 5, training loss: 2.003553Epoch: 7, batch: 6, training loss: 2.110098Epoch: 7, batch: 7, training loss: 1.853201Epoch: 7, batch: 8, training loss: 1.843372Epoch: 7, batch: 9, training loss: 2.356719Epoch: 7, batch: 10, training loss: 2.382624Epoch: 7, batch: 11, training loss: 2.668341Epoch: 7, batch: 12, training loss: 2.388415Epoch: 7, batch: 13, training loss: 2.862111Epoch: 7, batch: 14, training loss: 2.444305Epoch: 7, batch: 15, training loss: 3.075715Epoch: 7, batch: 16, training loss: 2.692372Epoch: 7, batch: 17, training loss: 2.634926Epoch: 7, batch: 18, training loss: 2.358064Epoch: 7, batch: 19, training loss: 1.879931Epoch: 7, batch: 20, training loss: 2.713087Epoch: 7, batch: 21, training loss: 2.050982Epoch: 7, batch: 22, training loss: 2.680896Epoch: 7, batch: 23, training loss: 2.478950Epoch: 7, batch: 24, training loss: 2.515468Epoch: 7, batch: 25, training loss: 2.818645Epoch: 7, batch: 26, training loss: 2.826506Epoch: 7, batch: 27, training loss: 2.902056Epoch: 7, batch: 28, training loss: 3.174736Epoch: 7, batch: 29, training loss: 2.941095Epoch: 7, batch: 30, training loss: 3.049224Epoch: 7, batch: 31, training loss: 2.556561Epoch: 7, batch: 32, training loss: 2.423295Epoch: 7, batch: 33, training loss: 3.475759Epoch: 7, batch: 34, training loss: 3.451646Epoch: 7, batch: 35, training loss: 2.847017Epoch: 7, batch: 36, training loss: 2.810891Epoch: 7, batch: 37, training loss: 2.735511Epoch: 7, batch: 38, training loss: 2.884470Epoch: 7, batch: 39, training loss: 3.421980Epoch: 7, batch: 40, training loss: 2.443585Epoch: 7, batch: 41, training loss: 2.786414Epoch: 7, batch: 42, training loss: 2.896767Epoch: 7, batch: 43, training loss: 2.433414Epoch: 7, batch: 44, training loss: 3.145386Epoch: 7, batch: 45, training loss: 3.031024Epoch: 7, batch: 46, training loss: 3.005503Epoch: 7, batch: 47, training loss: 2.960888Epoch: 7, batch: 48, training loss: 2.655961Epoch: 7, batch: 49, training loss: 2.910804Epoch: 8, batch: 0, training loss: 2.707167Epoch: 8, batch: 1, training loss: 2.990102Epoch: 8, batch: 2, training loss: 2.016523Epoch: 8, batch: 3, training loss: 2.865215Epoch: 8, batch: 4, training loss: 1.659360Epoch: 8, batch: 5, training loss: 1.814851Epoch: 8, batch: 6, training loss: 1.827572Epoch: 8, batch: 7, training loss: 1.725507Epoch: 8, batch: 8, training loss: 1.748452Epoch: 8, batch: 9, training loss: 2.124705Epoch: 8, batch: 10, training loss: 2.251073Epoch: 8, batch: 11, training loss: 2.545619Epoch: 8, batch: 12, training loss: 2.271243Epoch: 8, batch: 13, training loss: 2.723132Epoch: 8, batch: 14, training loss: 2.360713Epoch: 8, batch: 15, training loss: 2.950918Epoch: 8, batch: 16, training loss: 2.580857Epoch: 8, batch: 17, training loss: 2.534095Epoch: 8, batch: 18, training loss: 2.282991Epoch: 8, batch: 19, training loss: 1.800479Epoch: 8, batch: 20, training loss: 2.605109Epoch: 8, batch: 21, training loss: 2.097034Epoch: 8, batch: 22, training loss: 2.611790Epoch: 8, batch: 23, training loss: 2.376520Epoch: 8, batch: 24, training loss: 2.409878Epoch: 8, batch: 25, training loss: 2.702480Epoch: 8, batch: 26, training loss: 2.726752Epoch: 8, batch: 27, training loss: 2.813346Epoch: 8, batch: 28, training loss: 3.069502Epoch: 8, batch: 29, training loss: 2.821067Epoch: 8, batch: 30, training loss: 2.920751Epoch: 8, batch: 31, training loss: 2.451379Epoch: 8, batch: 32, training loss: 2.339528Epoch: 8, batch: 33, training loss: 3.254765Epoch: 8, batch: 34, training loss: 3.215334Epoch: 8, batch: 35, training loss: 2.741993Epoch: 8, batch: 36, training loss: 2.680384Epoch: 8, batch: 37, training loss: 2.604790Epoch: 8, batch: 38, training loss: 2.771148Epoch: 8, batch: 39, training loss: 3.276608Epoch: 8, batch: 40, training loss: 2.302043Epoch: 8, batch: 41, training loss: 2.667153Epoch: 8, batch: 42, training loss: 2.766860Epoch: 8, batch: 43, training loss: 2.341681Epoch: 8, batch: 44, training loss: 3.013493Epoch: 8, batch: 45, training loss: 2.913061Epoch: 8, batch: 46, training loss: 2.880614Epoch: 8, batch: 47, training loss: 2.819844Epoch: 8, batch: 48, training loss: 2.557608Epoch: 8, batch: 49, training loss: 2.801410Epoch: 9, batch: 0, training loss: 2.626343Epoch: 9, batch: 1, training loss: 2.874273Epoch: 9, batch: 2, training loss: 1.912105Epoch: 9, batch: 3, training loss: 2.713372Epoch: 9, batch: 4, training loss: 1.559980Epoch: 9, batch: 5, training loss: 1.744175Epoch: 9, batch: 6, training loss: 1.686037Epoch: 9, batch: 7, training loss: 1.562909Epoch: 9, batch: 8, training loss: 1.608447Epoch: 9, batch: 9, training loss: 1.975518Epoch: 9, batch: 10, training loss: 2.189086Epoch: 9, batch: 11, training loss: 2.480873Epoch: 9, batch: 12, training loss: 2.186983Epoch: 9, batch: 13, training loss: 2.629409Epoch: 9, batch: 14, training loss: 2.281479Epoch: 9, batch: 15, training loss: 2.820449Epoch: 9, batch: 16, training loss: 2.468576Epoch: 9, batch: 17, training loss: 2.454511Epoch: 9, batch: 18, training loss: 2.199188Epoch: 9, batch: 19, training loss: 1.752538Epoch: 9, batch: 20, training loss: 2.510200Epoch: 9, batch: 21, training loss: 1.907393Epoch: 9, batch: 22, training loss: 2.484830Epoch: 9, batch: 23, training loss: 2.309407Epoch: 9, batch: 24, training loss: 2.345874Epoch: 9, batch: 25, training loss: 2.626048